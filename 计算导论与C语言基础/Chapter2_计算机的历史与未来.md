# [计算机的历史与未来](https://www.coursera.org/learn/jisuanji-biancheng/lecture/GMlvB/li-shi-shang-de-ji-suan-she-bei)
> [计算机硬件历史](https://en.wikipedia.org/wiki/History_of_computing_hardware)(From Wikipedia, the free encyclopedia)
---
## 1. 历史上的计算设备
---
- 早期的计算机
  - 手工计算器，1200年~1600年
  - 机械计算器，1600年~1930年
  - 计算机原型，1937年~1946年
  ---
- 现代计算机（电子计算机）
  - 电子管计算机，1946年
  - 晶体管计算机，20世纪50年代后期
  - 集成电路计算机，1965年
  - 超大规模集成电路，20世纪70年代早期
  - 未来的第五代
  ---
- 早期的手工计算辅助工具
  > 算盘，Napier乘除器（1617），Oughtred计算尺（1621）
  - 共同特点
    - 无法记录计算法则 
    - 无法设定计算步骤
  - 作用
    - 标记计算过程
    - 记录计算结果
    - 进行数字计算的辅助工具
  ---
- 普遍认为的第一台机械计算器
  - [帕斯卡](https://zh.wikipedia.org/wiki/%E5%B8%83%E8%8E%B1%E5%85%B9%C2%B7%E5%B8%95%E6%96%AF%E5%8D%A1)
    - 12岁独自发现了“三角形的内角和等于180°”
    - 16岁参加巴黎数学家和物理学家哦小组
    - 17岁写成《圆锥截线论》 震惊数学家笛卡尔
    - 18岁时开始设计计算机，帮助父亲计算税率税款
    - 19岁第三个模型在1642年研制成功
  - 帕斯卡加法器（1642）
    - 是一种系列齿轮组成的装置，依靠发条转动，用专用的铁笔拨动转轮以输入数字  
    - 开始只能够做6位加法和减法
  ---
- 1958年后发现更早的机械计算器
  - 契克卡德(W.Schickard)
    - 德国科学家，当时在图宾根(Tubingen)大学任骄傲收。他广泛涉猎天文学、数学和测量学等诸多领域。
    - 1623年，契克卡德教授为自己的挚友----天文学家开普勒(Kepler)制作了一种机械计算机。
    - 契克卡德计算机可以进行6位数加减法，或许设置了某种“溢出”响铃装置。
    - 机器上部附加一套圆柱形“纳皮尔算筹”，因此也能进行乘除运算。
  ---
- 工业革命前的机械计算器
  - [莱布尼兹(G.W.Leibnitz,1646-1716)](https://zh.wikipedia.org/wiki/%E6%88%88%E7%89%B9%E5%BC%97%E9%87%8C%E5%BE%B7%C2%B7%E8%8E%B1%E5%B8%83%E5%B0%BC%E8%8C%A8)
  - 德国未来的数学家，提出了“二进制”的概念
  - 1673你那他在帕斯卡加法器的基础上，建造了一台能够进行四则运算的机械计算机器，轰动整个欧洲。
  - 仍然用齿轮及刻度盘操作，计算结果可以达到16位
  ---
- 工业革命时代的机械计算器
  - 1822年英国科学家巴贝奇(Babbage)制造出第一台差分机
    - 它可以处理3个不同的5位数
    - 计算精度达到6位小数
  - 1834年巴贝奇提出了分析及的概念
    - 机器共分为三个部分：堆栈，运算器，控制器
    - 企图用机械方式（蒸汽动力）实现计算过程
    - 计算用的程序和数据存储于穿孔卡片上
  - 阿达.奥古斯塔(Ada Augusta)
    - 为分析机编制了人类历史上第一批计算机程序
  ---
- 机械计算器的不断发展
  - 统计学家[霍列瑞斯(Hollerith)]()
    - 源自美国人口普查
      - 1880年的人口普查1887年才完成
      - 1890年的可能需要到1900年才能完成
    - Hollerith制表机（电子穿孔卡片汇总）应运而生，6个月即完成1890年人口普查数据汇总，随后两年内完成所有统计工作
    - 1896年，Hollerith成立“计算制表记录公司”，1924年改名"国际商用机器公司”
    - 1935年：IBM制造了IBM601穿孔卡片式计算机，能够在一秒钟内计算出乘法运算
  ---
- 采用电气元件的“计算机原型”
  - 1934年德国工程师楚泽(K.Zuse)开始研制Z1、Z2、Z3三种型号的计算机
    - 采用二进制的运算方式
    - 以继电器为主要元件
  - 1941年Zuse完成了Z3的研制工作
    - 第一台可编程的电子计算机
    - 可处理7位指数、14为小数
    - 使用了大量的真空管
    - 每秒能作3到4次加法运算
    - 一次乘法需要3到5秒
  ---
- 普遍认为的“第一台计算机”
  - [ENIAC(Electronic Numeric Integrator and Computer) 电子数字积分机算机](https://zh.wikipedia.org/wiki/%E9%9B%BB%E5%AD%90%E6%95%B8%E5%80%BC%E7%A9%8D%E5%88%86%E8%A8%88%E7%AE%97%E6%A9%9F)
  ---
- 从ENIAC到EDVAC
  - [EDVAC(Electronic Discrete Variable Automatic Computer) 电子离散变量自动计算机](https://zh.wikipedia.org/wiki/EDVAC)
   - 1945年3月，计算技术的先驱[冯·诺依曼(John con Neumann)](https://zh.wikipedia.org/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E5%86%AF%C2%B7%E8%AF%BA%E4%BC%8A%E6%9B%BC)来到摩尔学院Mauchly和Echert进行了两天讨论，拟定了存储程序式的电子计算机的方案。方案经冯·诺依曼整理后于1945年6月发表——存储程序控制原理
   - EDVAC于1952年制造完成
   - EDVAC是世界上第一台存储程序计算机
   - 是所有现代计算机的原型和范本
## 2. 从电子管到云计算
---
> 早期计算机（早期）目标：如何实现自动的计算？<br/>
  现代计算机（当前）目标：计算如何更快速、更方便、更经济？
---
- 第一代计算机
  - 时间：20世纪40、50年代
  - 主要特点
    - 使用真空管存储数据
      - 真空管是一种控制真空中电子流动的电子装置
      - 被设置为两个状态以表示0或1
      - 响应比机械快，但体积大、能耗高、易烧坏
      - EDVAC有18000个真空管，第一年运行就替换了19000个
    - 只能使用0/1进行编程
      - 000000000000111111111111110101000011111001..............
  ---
- 第二代计算机
  - 始于20世纪50年代后期
  - 主要特点
    - 使用晶体管存储数据
      - 晶体管由[贝尔实验室](https://zh.wikipedia.org/wiki/%E8%B4%9D%E5%B0%94%E5%AE%9E%E9%AA%8C%E5%AE%A4)于1947年发明
      - 功能与真空管类似，但更小、更便宜、功耗更少、更可靠
    - 产生操作系统
      - 标准化的硬件资源管理
      - 但不可移植
    - 产生高级编程语言
      - Fortran，Cobol
  ---
- 第三代计算机
  - 始于1965年
  - 主要特点
    - 使用集成电路
      - 集成电路可将成千上万的真空管或晶体管压在一个单独的微型芯片上
      - 1958年由德州仪器公司发明
    - 操作系统可移植
    - C语言产生
  ---
- 第四代计算机
  - 始于20世纪70年代
  - 主要特点
    - 使用超大规模集成电路
    - 更快、更小、更便宜
  - 第一块微处理器是1971年制造的Intel 4004
    - 2400个晶体管，计算能力与ENIAC相当
    - 但尺寸只有3mm × 2mm
    - 而ENIAC尺寸为30米长，3米高
  - 计算机发展出现瓶颈
    - 硬件、软件全方位地出现瓶颈
    - 第5代计算机正在酝酿中。。。。。
  ---
- > 摩尔定律
  > - 1965年Intel公司创始人之一G.Moore提出
  >   - 芯片密度每18个月增加1倍
  >     - 1972年第一代Intel 4004芯片总共不到3000晶体管
  >     - Intel Pentium芯片元件数达到千万数量级
  >   - CPU性能价格比大约18个月翻一番
  >     - 芯片工作速度已经达到10000MIPS的工作频率(MIPS,Million Instruction Per Second)
  >     - 速度越来越快，价格越来越便宜

- > 计算机分类
  > - 微型计算机(microcomputer)
  >   - 芯片密度每18个月增加1倍
  >     - 工作站(Workstation超级微机)
  >       - 强大的图形功能，用于计算机辅助设计
  >     - 个人桌面计算机(PC)
  > - 服务器（小型机、中型机）
  >     - 速度快、存储容量大、稳定、多个处理器，为多个用户服务
  >     - 可安装Windows系统，大多安装Linux系统
  >     - 速度较快，一般用于专业领域的桌面计算机
  > - 大型计算机
  >   - 速度快、体积庞大、价格昂贵，用于一般的大型公司，银行和研究单位，具有很强的管理能力
  > - 巨型计算机
  >   - 功能最强，速度最快（几万亿次）
  >   - n万亿次以上浮点运算/秒
  >   - 天气预报、地震分析、人工智能、数据可视化
  >   - 国家科技水平的重要标志   
  ---
## 3. 摩尔定律下的计算危机
  ---
- 问题之二：晶体管的大小限制
  - 如果晶体管仍然持续不断地变小，他们很快就会变到一个院子那么大。任何纳米管和传统工艺都对这种情况没有办法。
  ---
- 问题之三：电泄露
  - 随着晶体管体积的不断缩小，其电泄露的情形也不断增加，越来越影响芯片的计算能力。
  ---
- 问题之一：散热
  - 随着晶体管密度与速度的增加，芯片会消耗更多的电力，产生更多的热能。
  ---
- > 摩尔定律失效以后要考虑全新的计算机理论和计算模式。
  ---
## 4. 量子计算机的基本原理
---
> [量子计算机](https://zh.wikipedia.org/wiki/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E6%9C%BA)(From Wikipedia, the free encyclopedia)
---
-  在传统的计算机中，一个比特，例如一个电子管或者一个存储位，在某一个 时刻呢，它只能保持一种状态。这个状态呢要嘛表示1要嘛表示0。 那么在量子计算机中呢，也有一个量子比特，用来存储数据的。但是 量子比特与传统的计算机比特完全不同。一个量子比特可以同时保持多种状态。 这就意味着一个量子比特可以同时存储多个数。 我们打个比方。 比方说啊在传统的计算机中两个比特 在某一个时刻只能存储一对0和1。 也就是说这四种情况之一在传统的计算机中可以存储。 那么在量子计算机中呢，两个比特在某一个时刻可以同时存储 4对0和1。也就是说在传统的计算机中， 如果我们想要存储下4对0和1的组合，我们就需要2乘以4，8个比特。 但是在量子计算机中呢两个量子比特在某个时候呢就能够 同时存储4对0和1了。那么扩展一下， 在传统的计算机中N个比特在某一个时刻 只能存储2的N次幂个数之一 那么对于量子计算机而言呢，N个量子比特在某一个确定的时刻可以同时 把这2的N次幂个数存储下来，那这个就跟传统的计算机完全不同了。 
- 但不仅如此，不只是存储上存在这样的差异， 在计算上也有不同。在经典的计算机里头， 比方说我们输入的是一个N位的2进制数，那么进行一次操作， 进行一次运算我们只能得到一个相应的计算结果。 那么对于量子计算机就不同了。如果我们有N个量子比特， 我们可以在同一时刻同时输入2的N次幂个输入数据。 并且经过一次运算我们能够同时获得2的N次幂个 计算结果。哇，这是一个非常强的并行计算 的能力。跟现有的计算机完全不同。
- 那经典计算机和 量子计算机的计算能力到底有多大的差异呢。 我们来看这样一个对比。 那么刚才我们提到的2013年的6月INTEL推出的这个酷睿的处理器中已经容纳了大约14亿个 晶体管。也就是说我们用了 14亿个晶体管来制造这样一个CPU。啊这个是一个 庞大的数目。我们再来看量子比特。理论上讲， 那么300个量子比特它所能表达的数据的个数是2的300次方。这是一个 非常巨大的数字。据说呢这个数字超过了整个宇宙的原子数量的 总和。我看到了这个结果但不知道这个结果是怎么计算的。因为我不知道宇宙有 多大。好，这只是一个理论上的值。那么在现实计算中呢我们 达不到这样的结果。因为量子状态的保持和提取呢是具有一定的成功概率的。 那为了保证计算过程的准确，我们就需要利用多个量子比特位同时进行计算。 利用冗余的办法获得比较高的准确率。所以我们需要很多的 物理量子比特才能获得一个可容错的逻辑量子比特。 那么计算了这个冗余以后，我们也只需要大约1000个量子比特就能够超越传统计算机的 这种计算能力了。这是一个非常非常可观的一个数字。 
- 那既然量子计算机的计算能力如此之强，那为什么我们不赶快制造一台呢？ 因为它是有困难的。下面我们来说一下实现量子计算的难点。 刚才啊我们提到， 量子呢可以在同一个时刻同时保持 多种状态。我们可以利用量子这个特性进行计算。 **但是有一个条件，它不能受到外界环境的 干扰。但这就产丧生了一个问题。如果我们不去打扰它。那我们怎么去 观测这个量子所具有的状态呢。如果我们观测不到 这个量子的状态，那它保持着多少种状态也是没有用的。 所以说这就形成了一个矛盾**。那么对于量子而言，只有与外界环境 隔离才能保持良好的相干性。对于量子计算机的制造而言呢， 只有把量子与外界的环境建立良好的耦合， 才能够控制演化并且读出结果。 这就形成了一个矛盾。那这就是当前量子计算机研制中碰到的一个最大的问题。 有问题不要紧，我们就要想办法研究它。 为了要让量子计算机的实现基础人们进行了各种各样的努力。 提出了各种各样的方法。比方说基于核磁共振的系统。基于超导量子比特的系统。这个系统呢 待会儿我们会，还会提到。比方说还有 基于光量子比特的这个系统。基于量子阱的系统。 当然量子阱是用来捕获量子的一种系统啊。那么基于腔量子电动力学的系统 等等等等。各种各样的研究。那么人们做了这么多的研究。 取得了哪些成果呢。那下面我们介绍一下当前量子计算所取得的一些主要的成就。

  ---
## 5.量子计算成果简介
---
- 那么人们做了这么多的研究，取得了哪些成果呢? 那下面我们介绍一下，当前量子计算所取得的一些主要的成就。 
- 那么早在2009年的11月份，美国的国家标准技术研究院 就曾经发布过一台量子计算机的原型。这台量子计算机呢，具有两个量子比特位。 在这台计算机里头，他们把两个镁离子和两个铍离子限定在离子阱中。 用铍离子呢，来存储量子比特。镁离子呢，当作稳定剂。然后呢，使用激光脉冲逻辑门， 对量子比特呢，进行操作。经过他们的实验，每个量子逻辑门的准确率都可以达到百分之九十以上。 那这是一个不错的进步了。当然了， 只有把这个准确率提升到百分之99.99， 甚至9999， 才能够用它来做实用的量子计算机。但毕竟已经取得了一个很大的进步了。
- 那么除此之外呢，在2011年的5月，德国的马克斯-普朗克，他们首次实现了用单个原子来存储量子信息。 这跟我们的理论模型就比较接近了。在他们的实验里头呢， 他们用共振器和激光把单个光子的量子状态写入到一个铷原子里头，并且成功的读出来了。 在实验中的百分之九十的情况下，读出的这个量子信息跟保存进去的是一致的。 最关键的呢，他们还获得了一个相对比较长的存储时间。 可是这个量子信息能在铷原子中存储大约180微秒，这已经是非常大的一个进步了。 当然，这个时间距离真正制造量子计算机的要求还是相距甚远。那么，除了科研机构之外， 很多的公司也在作相应的研制。比方说，IBM。 
- 在2010年11月，IBM的托马斯-沃森研究中心，这是IBM非常非常有名的一个研究中心了， 他们组建了一支庞大的研究团队，专门开展量子计算机的研究。他们计划干五年。他们所采用的技术呢， 就是基于‘金属的超导性原理‘来制备量子计算机。 那么在2012年的2月，IBM的团队呢， 在一个容纳3个量子比特的芯片上， 构造了能够执行‘与非‘运算的装置，并且把运算的成功率 提高到了95%。那这是一个非常好的成果了。 那么有一个专门研究量子计算的教授呢就曾经讲过， IBM的这个成果已经触碰倒了胜利的边缘。那么刚才我们介绍的这些呢， 基本上都是在研究领域，在量子计算机方面的一些比较新的进展。 那么在工业界有没有什么动向呢? 还真的有。 
- 早在2011年的时候，加拿大呢有一个公司叫做D-Wave Systems, 这个公司呢，就推出了，就推出了，号称全球第一台 商用实用型量子计算机。这个呢，这个当然对业界的震动是比较大的。 别人还在搞研究呢，他已经可以推出产品了。那这个，大家都比较关注。 这台计算机呢，叫D-Wave One。 它呢，也是基于超低温下的超大技术来实现的。 从这个图上呢，我们可以看得出，这个呢是这个计算机的一个主体。 这个呢，是用来隔绝外部噪音和信号的过滤器。 这边呢，是这个计算机的大小，我们可以看到这是一台非常大的一台计算机。 那么站着的这个人呢是D-Wave公司的总裁。过会呢，我们还会提到他。 那么在最近，就是2013年的5月，D-Wave公司在D-Wave One的基础上呢推出了D-Wave Two计算机。 那么D-Wave Two呢比D-Wave One更加的先进。比方说它的量子位的数量， 达到了512个，这个就更加接近于我们讲过的1000个量子位的数量了。 而且呢，它真的，最关键的呢， 它真的达成了一个交易。因为今年的5月份， 谷歌，美国航天局NASA以及美国大学空间研究联合会，他们共同成立了 一个量子人工智能的实验室。 并且呢，他们买入了一台D-Wave Two量子计算机。 这个对业界的震动就非常非常大了。 我们来看一下，这个呢，是D-Wave Two的这个机箱。我们可以 看到他依然非常的庞大。可以进去一个人。比方说，Rose呢， 就是走到这个计算机里头，站在这个机器的旁边拍了一张照片。旁边就是这个机器了。 看上去是非常非常大的。那我们给一个近景来看一下这台机器。 这台机器呢，它也是工作在超低温的环境之下。 所以说它需要一个庞大的机箱。 这个机箱不是用来，不只是用来放这个机器， 主要是放这个冷却设备的。 我们可以看到在这儿有一个很大的冷却塔。一层层的降温的冷却塔。 那么在这个冷却塔的顶端呢，就会有一个装置， 在这个装置里面固定了一颗量子芯片。 就是D-Wave Two。那么谷歌和NASA他们买来之后要做些什么呢? 当然谷歌感兴趣的领域，他们用来做一些比如说语音搜索啊，图像检索啊， Big Data 大数据。NASA呢，当然是感兴趣的就是关于宇宙的一些东西，比方说 行星的大气，以及行星碰撞或者是星系碰撞的一种模拟， 再就是关于病毒的一些分析，比方说，我们要做一些病毒的模拟， 再来就是关于气候的变化，需要一些巨量的计算的。比方说海啸的一种模拟。那么我们可以知道海啸将会波及到哪里，就是计算出来。 那么，关于这两台计算机是不是真正的 量子计算机呢?人们也有一些争论。有的研究人员呢，就认为， 这样的量子芯片呢，是使用超低温环境下呈超导状态的金属来构造的。 那它是用了电流的流向来模拟量子态。 所以说有研究人员认为呢，一方面，它没有实现真正的这种量子纠缠， 而另一方面呢，它也没有利用量子门电路来对量子进行控制。 那么D-Wave公司呢也承认， 那么D-Wave One呢，它的基础架构和生产工艺都是基于现有的半导体产业的一些成果的基础之上而构造出来的。 它只是对现有计算机的一个补充和增强。那我们从这个我们可以看到， 那么量子计算机呢，已经出现了有一些比较大的程式，但是 要真正做到并且实现我们想象中的量子计算机， 还是需要一些时间的。那么D-Wave公司的创始人呢，就是这个Rose, 他呢，还模仿摩尔提出来了一个新的Rose定律。
- 刚刚我们讲摩尔定律，这个是Rose定律。 是关于量子计算机发展状况的一个预测。根据他的预测呢，到2014年的时候就是明年的时候，那么 人类呢可能能制备出来具备1000个量子比特的量子计算机。也就是说，到明年的时候啊， 我们的这个量子计算机在完成一般性计算就是各种普通计算的时候， 大概跟现有计算机它的计算能力已经持平了这个计算机。OK. 这就是目前量子计算机的一个状态。 说了这么多，我们想让大家知道的就是目前的计算机发展是真成了 变革的前域。 我们就处在这样的一个位置。其实呢，在计算机领域里头还真有这么一个规律。我们把计算机领域里的15年周期律。 什么意思呢?我们回顾一下你就明白了。 我们说1965年前后，回顾一下计算机产生以后， 1965年前后，那个时候真的有一次巨大的变革那么，那个时候大型计算机出来以后呢， 人们觉得，哎呀，这个东西怎么有那么强大的计算能力啊。 引起了一场革命。 那再过15年，到了1980年的时候，personal computer走入人们的家庭了。 到现在为止，你看它已经彻底改变了我们的生活。所以说 已引发了一场科技的革命。再过15年在1995年前后的时候，哪个时候呢， Internet逐渐走入了人们的家里了。当然那个时候中国有因特网的人还很少。但是 在其他的国家可能用因特网的国家非常的普及。我们也知道，中国进步非常得快， 这些年，因特网的普及程度可能比国外的某些地方还要好得多。因特网的深入使用 引发了一场变革，1995年。 如果这个时间再增加15年，恰好是2010年前后， 我们现在处于2010年以后的一个状态。 那么，是不是又要什么东西引发一场革命呢? 我不知道。 但是我觉得，关于计算能力这方面的探讨， 至少是一个当代计算机科学很值得探讨的一个问题。 那么在这儿呢我就想跟大家 分享一下我自己的感受。 你们处在这样一个变革的时期，你们手上刚好有这样的一个机遇。 我知道很多的同学是从我们这个课开始了解计算机的。 我希望大家能在不远的将来成为引领这个世界变化的人。OK,那我们的这次专题呢，我们就讲到这儿。 最后，谢谢大家。 